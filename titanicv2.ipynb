{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"},{"sourceId":7252078,"sourceType":"datasetVersion","datasetId":4201848}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Input data files are available in the read-only \"../input/\" directory|\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-03T06:38:07.488801Z","iopub.execute_input":"2024-01-03T06:38:07.489215Z","iopub.status.idle":"2024-01-03T06:38:07.910460Z","shell.execute_reply.started":"2024-01-03T06:38:07.489182Z","shell.execute_reply":"2024-01-03T06:38:07.909608Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic-competition/train.csv\n/kaggle/input/titanic-competition/test.csv\n/kaggle/input/titanic-competition/gender_submission.csv\n/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"gender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:27.509243Z","iopub.execute_input":"2024-01-03T06:38:27.509660Z","iopub.status.idle":"2024-01-03T06:38:27.528769Z","shell.execute_reply.started":"2024-01-03T06:38:27.509628Z","shell.execute_reply":"2024-01-03T06:38:27.527867Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def substrings_in_string(big_string, substrings):\n    for substring in substrings:\n        if substring in big_string:\n            return substring\n    print(big_string)\n    return np.nan\n    return 'Unknown'\n\ntitle_list = ['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n              'Dr', 'Ms', 'Mlle', 'Col', 'Capt', 'Mme', 'Countess',\n              'Don', 'Jonkheer']\n\ndef extract_title(name):\n    for title in title_list:\n        if title in name:\n            return title\n    return 'Other'\n\n# Example usage:\nnames = ['Mrs. Smith', 'Mr. Johnson', 'Miss. Davis', 'Dr. Brown']\n\nfor name in names:\n    title = extract_title(name)\n    print(f\"Name: {name}, Title: {title}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:27.678335Z","iopub.execute_input":"2024-01-03T06:38:27.679063Z","iopub.status.idle":"2024-01-03T06:38:27.687861Z","shell.execute_reply.started":"2024-01-03T06:38:27.679026Z","shell.execute_reply":"2024-01-03T06:38:27.686715Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Name: Mrs. Smith, Title: Mrs\nName: Mr. Johnson, Title: Mr\nName: Miss. Davis, Title: Miss\nName: Dr. Brown, Title: Dr\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# I recombine them into four categories","metadata":{}},{"cell_type":"code","source":"train['Title'] = train['Name'].map(lambda x: substrings_in_string(x, title_list))\n\n# replacing all titles with 'Mr', 'Mrs', 'Miss', 'Master'\ndef replace_titles(x):\n    title = x['Title']\n    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n        return 'Mr'\n    elif title in ['Countess', 'Mme']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title == 'Dr':\n        if x['Sex'] == 'Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\n\ntrain['Title'] = train.apply(replace_titles, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:28.232502Z","iopub.execute_input":"2024-01-03T06:38:28.232884Z","iopub.status.idle":"2024-01-03T06:38:28.255530Z","shell.execute_reply.started":"2024-01-03T06:38:28.232854Z","shell.execute_reply":"2024-01-03T06:38:28.254099Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def substrings_in_string(big_string, substrings):\n    if pd.isna(big_string):\n        return 'Unknown'\n    \n    for substring in substrings:\n        if substring in big_string:\n            return substring\n    return 'Unknown'\n\ncabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\ntest['Deck'] = test['Cabin'].map(lambda x: substrings_in_string(str(x), cabin_list))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:28.416438Z","iopub.execute_input":"2024-01-03T06:38:28.417414Z","iopub.status.idle":"2024-01-03T06:38:28.425890Z","shell.execute_reply.started":"2024-01-03T06:38:28.417378Z","shell.execute_reply":"2024-01-03T06:38:28.424709Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Exploring the datasets:","metadata":{}},{"cell_type":"code","source":"gender_submission.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:28.772837Z","iopub.execute_input":"2024-01-03T06:38:28.773790Z","iopub.status.idle":"2024-01-03T06:38:28.783627Z","shell.execute_reply.started":"2024-01-03T06:38:28.773752Z","shell.execute_reply":"2024-01-03T06:38:28.782546Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived\n0          892         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:28.930735Z","iopub.execute_input":"2024-01-03T06:38:28.931120Z","iopub.status.idle":"2024-01-03T06:38:28.945870Z","shell.execute_reply.started":"2024-01-03T06:38:28.931089Z","shell.execute_reply":"2024-01-03T06:38:28.944805Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Pclass              Name   Sex   Age  SibSp  Parch  Ticket  \\\n0          892       3  Kelly, Mr. James  male  34.5      0      0  330911   \n\n     Fare Cabin Embarked     Deck  \n0  7.8292   NaN        Q  Unknown  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Deck</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Unknown</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:29.075175Z","iopub.execute_input":"2024-01-03T06:38:29.075584Z","iopub.status.idle":"2024-01-03T06:38:29.093474Z","shell.execute_reply.started":"2024-01-03T06:38:29.075550Z","shell.execute_reply":"2024-01-03T06:38:29.092184Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked Title  \n0      0         A/5 21171   7.2500   NaN        S    Mr  \n1      0          PC 17599  71.2833   C85        C   Mrs  \n2      0  STON/O2. 3101282   7.9250   NaN        S  Miss  \n3      0            113803  53.1000  C123        S   Mrs  \n4      0            373450   8.0500   NaN        S    Mr  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n# Display columns with missing values and their counts\nmissing_values = train.isnull().sum()\nprint(\"Columns with missing values:\")\nprint(missing_values[missing_values > 0])","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:29.241578Z","iopub.execute_input":"2024-01-03T06:38:29.242630Z","iopub.status.idle":"2024-01-03T06:38:29.251974Z","shell.execute_reply.started":"2024-01-03T06:38:29.242589Z","shell.execute_reply":"2024-01-03T06:38:29.250796Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Columns with missing values:\nAge         177\nCabin       687\nEmbarked      2\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Impute missing values for specific columns\nimputer = SimpleImputer(strategy='most_frequent')  # You can use different strategies (mean, median, constant) based on the data\ncolumns_to_impute = ['Age', 'Embarked']  # Columns to impute missing values\ntrain[columns_to_impute] = imputer.fit_transform(train[columns_to_impute])\n\n# Check if missing values have been filled\nmissing_values_after_imputation = train[columns_to_impute].isnull().sum()\nprint(\"\\nMissing values after imputation:\")\nprint(missing_values_after_imputation)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:29.425044Z","iopub.execute_input":"2024-01-03T06:38:29.425454Z","iopub.status.idle":"2024-01-03T06:38:29.449804Z","shell.execute_reply.started":"2024-01-03T06:38:29.425419Z","shell.execute_reply":"2024-01-03T06:38:29.448712Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\nMissing values after imputation:\nAge         0\nEmbarked    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Perform one-hot encoding for 'Sex', 'Embarked', and 'Title' columns\ntrain = pd.get_dummies(train, columns=['Sex', 'Embarked', 'Title'])\n\n# Display the updated DataFrame with one-hot encoded columns\nprint(train.head())","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:30.079625Z","iopub.execute_input":"2024-01-03T06:38:30.080017Z","iopub.status.idle":"2024-01-03T06:38:30.104519Z","shell.execute_reply.started":"2024-01-03T06:38:30.079985Z","shell.execute_reply":"2024-01-03T06:38:30.103285Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name   Age  SibSp  Parch  \\\n0                            Braund, Mr. Owen Harris  22.0      1      0   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n2                             Heikkinen, Miss. Laina  26.0      0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n4                           Allen, Mr. William Henry  35.0      0      0   \n\n             Ticket     Fare Cabin  Sex_female  Sex_male  Embarked_C  \\\n0         A/5 21171   7.2500   NaN       False      True       False   \n1          PC 17599  71.2833   C85        True     False        True   \n2  STON/O2. 3101282   7.9250   NaN        True     False       False   \n3            113803  53.1000  C123        True     False       False   \n4            373450   8.0500   NaN       False      True       False   \n\n   Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  \n0       False        True         False       False      True      False  \n1       False       False         False       False     False       True  \n2       False        True         False        True     False      False  \n3       False        True         False       False     False       True  \n4       False        True         False       False      True      False  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"Creating a new feature to represent the total family size by combining 'SibSp' and 'Parch' is a useful way to analyze the impact of family size on survival rates.","metadata":{}},{"cell_type":"code","source":"# Create a new feature 'Family_Size' by adding 'SibSp' and 'Parch' columns\ntrain['Family_Size'] = train['SibSp'] + train['Parch']\n\n# Display the updated DataFrame with the new 'Family_Size' feature\nprint(train[['SibSp', 'Parch', 'Family_Size']].head())","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:31.512332Z","iopub.execute_input":"2024-01-03T06:38:31.512752Z","iopub.status.idle":"2024-01-03T06:38:31.522767Z","shell.execute_reply.started":"2024-01-03T06:38:31.512721Z","shell.execute_reply":"2024-01-03T06:38:31.521607Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"   SibSp  Parch  Family_Size\n0      1      0            1\n1      1      0            1\n2      0      0            0\n3      1      0            1\n4      0      0            0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"2. Grouping rare titles or titles based on their social status can indeed be a beneficial feature engineering step.","metadata":{}},{"cell_type":"code","source":"# Extract titles from the 'Name' column\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# Display unique titles and their counts\nprint(train['Title'].value_counts())\n\n# Map titles to specific categories based on their rarity or social status\ntitle_mapping = {\n    'Mr': 'Mr',\n    'Miss': 'Miss',\n    'Mrs': 'Mrs',\n    'Master': 'Master',\n    'Dr': 'Rare',\n    'Rev': 'Rare',\n    'Col': 'Rare',\n    'Major': 'Rare',\n    'Mlle': 'Rare',\n    'Countess': 'Rare',\n    'Ms': 'Rare',\n    'Lady': 'Rare',\n    'Jonkheer': 'Rare',\n    'Don': 'Rare',\n    'Dona': 'Rare',\n    'Mme': 'Rare',\n    'Capt': 'Rare',\n    'Sir': 'Rare'\n}\n\n# Map the titles to their respective categories\ntrain['Title'] = train['Title'].map(title_mapping)\n\n# Display the updated DataFrame with the new 'Title' categories\nprint(train['Title'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:33.128417Z","iopub.execute_input":"2024-01-03T06:38:33.128981Z","iopub.status.idle":"2024-01-03T06:38:33.148247Z","shell.execute_reply.started":"2024-01-03T06:38:33.128938Z","shell.execute_reply":"2024-01-03T06:38:33.146688Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Title\nMr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nMlle          2\nMajor         2\nCol           2\nCountess      1\nCapt          1\nMs            1\nSir           1\nLady          1\nMme           1\nDon           1\nJonkheer      1\nName: count, dtype: int64\nTitle\nMr        517\nMiss      182\nMrs       125\nMaster     40\nRare       27\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"3. Extracting deck information from the 'Cabin' column and creating a new feature based on the deck letters can be done by parsing the cabin information and extracting the deck letters.","metadata":{}},{"cell_type":"code","source":"# Extracting the deck information from the 'Cabin' column\ntrain['Deck'] = train['Cabin'].str.slice(0, 1)  # Extract the first character of the 'Cabin' column\n\n# Display unique deck values and their counts\nprint(train['Deck'].value_counts())\n\n# Fill missing values with a specific category (if needed)\ntrain['Deck'].fillna('Unknown', inplace=True)  # Fill missing values with 'Unknown' category\n\n# Display the updated DataFrame with the new 'Deck' column\nprint(train[['Cabin', 'Deck']].head())","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:34.695941Z","iopub.execute_input":"2024-01-03T06:38:34.696332Z","iopub.status.idle":"2024-01-03T06:38:34.708498Z","shell.execute_reply.started":"2024-01-03T06:38:34.696300Z","shell.execute_reply":"2024-01-03T06:38:34.707644Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Deck\nC    59\nB    47\nD    33\nE    32\nA    15\nF    13\nG     4\nT     1\nName: count, dtype: int64\n  Cabin     Deck\n0   NaN  Unknown\n1   C85        C\n2   NaN  Unknown\n3  C123        C\n4   NaN  Unknown\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extracting prefixes from the 'Ticket' column\ntrain['Ticket_Prefix'] = train['Ticket'].apply(lambda x: x.split(' ')[0] if len(x.split(' ')) > 1 else 'NoPrefix')\n\n# Display unique ticket prefixes and their counts\nprint(train['Ticket_Prefix'].value_counts())\n\n# Display the updated DataFrame with the new 'Ticket_Prefix' column\nprint(train[['Ticket', 'Ticket_Prefix']].head())\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:35.328211Z","iopub.execute_input":"2024-01-03T06:38:35.328612Z","iopub.status.idle":"2024-01-03T06:38:35.342131Z","shell.execute_reply.started":"2024-01-03T06:38:35.328580Z","shell.execute_reply":"2024-01-03T06:38:35.340887Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Ticket_Prefix\nNoPrefix      665\nPC             60\nC.A.           27\nSTON/O         12\nA/5            10\nW./C.           9\nCA.             8\nSOTON/O.Q.      8\nSOTON/OQ        7\nA/5.            7\nCA              6\nSTON/O2.        6\nC               5\nF.C.C.          5\nS.O.C.          5\nSC/PARIS        5\nSC/Paris        4\nS.O./P.P.       3\nPP              3\nA/4.            3\nA/4             3\nSC/AH           3\nA./5.           2\nSOTON/O2        2\nA.5.            2\nWE/P            2\nS.C./PARIS      2\nP/PP            2\nF.C.            1\nSC              1\nS.W./PP         1\nA/S             1\nFa              1\nSCO/W           1\nSW/PP           1\nW/C             1\nS.C./A.4.       1\nS.O.P.          1\nA4.             1\nW.E.P.          1\nSO/C            1\nS.P.            1\nC.A./SOTON      1\nName: count, dtype: int64\n             Ticket Ticket_Prefix\n0         A/5 21171           A/5\n1          PC 17599            PC\n2  STON/O2. 3101282      STON/O2.\n3            113803      NoPrefix\n4            373450      NoPrefix\n","output_type":"stream"}]},{"cell_type":"markdown","source":"4. Convert the 'Age' feature into categorical bins representing different age groups using pandas' cut() function. This enables you to create age categories such as 'child', 'adult', 'elderly', etc., and analyze potential survival patterns among these groups","metadata":{}},{"cell_type":"code","source":"# Define the age bin edges and labels for different age groups\nage_bins = [0, 12, 18, 60, float('inf')]  # Define bin edges for 'child', 'teen', 'adult', and 'elderly'\nage_labels = ['Child', 'Teen', 'Adult', 'Elderly']  # Labels for different age groups\n\n# Create a new column 'Age_Group' containing the categorical age bins\ntrain['Age_Group'] = pd.cut(train['Age'], bins=age_bins, labels=age_labels, right=False)\n\n# Display unique values and counts in the 'Age_Group' column\nprint(train['Age_Group'].value_counts(dropna=False))\n\n# Display the updated DataFrame with the new 'Age_Group' column\nprint(train[['Age', 'Age_Group']].head())\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:36.854962Z","iopub.execute_input":"2024-01-03T06:38:36.855710Z","iopub.status.idle":"2024-01-03T06:38:36.871720Z","shell.execute_reply.started":"2024-01-03T06:38:36.855673Z","shell.execute_reply":"2024-01-03T06:38:36.870400Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Age_Group\nAdult      752\nChild       68\nTeen        45\nElderly     26\nName: count, dtype: int64\n    Age Age_Group\n0  22.0     Adult\n1  38.0     Adult\n2  26.0     Adult\n3  35.0     Adult\n4  35.0     Adult\n","output_type":"stream"}]},{"cell_type":"markdown","source":"5. Calculate the fare per person by dividing the 'Fare' by the 'Family Size' (including the individual), providing insights into survival based on ticket prices paid per person.","metadata":{}},{"cell_type":"code","source":"# Calculate fare per person by dividing 'Fare' by 'Family_Size'\ntrain['Fare_Per_Person'] = train['Fare'] / (train['Family_Size'] + 1)\n\n# Display the updated DataFrame with the new 'Fare_Per_Person' column\nprint(train[['Fare', 'Family_Size', 'Fare_Per_Person']].head())","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:38.468199Z","iopub.execute_input":"2024-01-03T06:38:38.468609Z","iopub.status.idle":"2024-01-03T06:38:38.481290Z","shell.execute_reply.started":"2024-01-03T06:38:38.468577Z","shell.execute_reply":"2024-01-03T06:38:38.479899Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"      Fare  Family_Size  Fare_Per_Person\n0   7.2500            1          3.62500\n1  71.2833            1         35.64165\n2   7.9250            0          7.92500\n3  53.1000            1         26.55000\n4   8.0500            0          8.05000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"6. Create a binary feature indicating missing values in a particular column (e.g., 'Cabin_missing', 'Age_missing') to leverage the information of missingness.","metadata":{}},{"cell_type":"code","source":"# Create binary indicators for missing values in 'Cabin' and 'Age' columns\ntrain['Cabin_missing'] = train['Cabin'].isnull().astype(int)\ntrain['Age_missing'] = train['Age'].isnull().astype(int)\n\n# Display the updated DataFrame with binary indicators for missing values\nprint(train[['Cabin', 'Cabin_missing', 'Age', 'Age_missing']].head())","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:38:39.470701Z","iopub.execute_input":"2024-01-03T06:38:39.471438Z","iopub.status.idle":"2024-01-03T06:38:39.482589Z","shell.execute_reply.started":"2024-01-03T06:38:39.471400Z","shell.execute_reply":"2024-01-03T06:38:39.481675Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"  Cabin  Cabin_missing   Age  Age_missing\n0   NaN              1  22.0            0\n1   C85              0  38.0            0\n2   NaN              1  26.0            0\n3  C123              0  35.0            0\n4   NaN              1  35.0            0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:39:23.719429Z","iopub.execute_input":"2024-01-03T06:39:23.720533Z","iopub.status.idle":"2024-01-03T06:39:23.743784Z","shell.execute_reply.started":"2024-01-03T06:39:23.720465Z","shell.execute_reply":"2024-01-03T06:39:23.742638Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 27 columns):\n #   Column           Non-Null Count  Dtype   \n---  ------           --------------  -----   \n 0   PassengerId      891 non-null    int64   \n 1   Survived         891 non-null    int64   \n 2   Pclass           891 non-null    int64   \n 3   Name             891 non-null    object  \n 4   Age              891 non-null    object  \n 5   SibSp            891 non-null    int64   \n 6   Parch            891 non-null    int64   \n 7   Ticket           891 non-null    object  \n 8   Fare             891 non-null    float64 \n 9   Cabin            204 non-null    object  \n 10  Sex_female       891 non-null    bool    \n 11  Sex_male         891 non-null    bool    \n 12  Embarked_C       891 non-null    bool    \n 13  Embarked_Q       891 non-null    bool    \n 14  Embarked_S       891 non-null    bool    \n 15  Title_Master     891 non-null    bool    \n 16  Title_Miss       891 non-null    bool    \n 17  Title_Mr         891 non-null    bool    \n 18  Title_Mrs        891 non-null    bool    \n 19  Family_Size      891 non-null    int64   \n 20  Title            891 non-null    object  \n 21  Deck             891 non-null    object  \n 22  Ticket_Prefix    891 non-null    object  \n 23  Age_Group        891 non-null    category\n 24  Fare_Per_Person  891 non-null    float64 \n 25  Cabin_missing    891 non-null    int64   \n 26  Age_missing      891 non-null    int64   \ndtypes: bool(9), category(1), float64(2), int64(8), object(7)\nmemory usage: 127.4+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"1. The process of dividing your dataset into training, validation, and test sets typically involves allocating a certain percentage of your data to each set.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train[['Title_Mr', 'Title_Mrs', 'Title_Master', 'Title_Miss', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Family_Size','Fare_Per_Person', 'Sex_male', 'Sex_female', 'Cabin_missing', 'Age_missing']]  # Features\ny = train['Survived']  # Target variable\n\n# Assuming your features are stored in X and the target variable in y\n# X contains your input features, and y contains the corresponding labels or outputs\n\n# Split the dataset into training and testing sets (80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Further split the training data into training and validation sets (70% training, 30% validation)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n\n# Now you have:\n# X_train, y_train -> Training set\n# X_val, y_val     -> Validation set\n# X_test, y_test   -> Test set\n\n# Ensure to replace 'X' and 'y' with your actual feature and target variable names respectively.\n# The 'random_state' parameter ensures reproducibility by fixing the random seed.","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:42:14.300046Z","iopub.execute_input":"2024-01-03T06:42:14.300491Z","iopub.status.idle":"2024-01-03T06:42:14.315840Z","shell.execute_reply.started":"2024-01-03T06:42:14.300459Z","shell.execute_reply":"2024-01-03T06:42:14.314580Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Model Selection, Training and Evaluation","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:59:37.766176Z","iopub.execute_input":"2024-01-03T04:59:37.766620Z","iopub.status.idle":"2024-01-03T04:59:37.772894Z","shell.execute_reply.started":"2024-01-03T04:59:37.766573Z","shell.execute_reply":"2024-01-03T04:59:37.771395Z"}}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Initialize the Logistic Regression model\nlogistic_model = LogisticRegression(random_state=42)\n\n# Train the model on the training data\nlogistic_model.fit(X_train, y_train)\n\n# Evaluate the model on the validation set\nvalidation_accuracy = logistic_model.score(X_val, y_val)\nprint(f\"Validation Set Accuracy (Logistic Regression): {validation_accuracy:.4f}\")\n\n# Evaluate the final performance on the test set\ntest_accuracy = logistic_model.score(X_test, y_test)\nprint(f\"Test Set Accuracy (Logistic Regression): {test_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:44:05.059356Z","iopub.execute_input":"2024-01-03T06:44:05.059813Z","iopub.status.idle":"2024-01-03T06:44:05.106888Z","shell.execute_reply.started":"2024-01-03T06:44:05.059776Z","shell.execute_reply":"2024-01-03T06:44:05.106040Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Validation Set Accuracy (Logistic Regression): 0.8271\nTest Set Accuracy (Logistic Regression): 0.7989\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Initialize the Support Vector Machine (SVM) model\nsvm_model = SVC(random_state=42)\n\n# Train the SVM model on the training data\nsvm_model.fit(X_train, y_train)\n\n# Evaluate the model on the validation set\nvalidation_accuracy = svm_model.score(X_val, y_val)\nprint(f\"Validation Set Accuracy (SVM): {validation_accuracy:.4f}\")\n\n# Evaluate the final performance on the test set\ntest_accuracy = svm_model.score(X_test, y_test)\nprint(f\"Test Set Accuracy (SVM): {test_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:44:45.720232Z","iopub.execute_input":"2024-01-03T06:44:45.720623Z","iopub.status.idle":"2024-01-03T06:44:45.758785Z","shell.execute_reply.started":"2024-01-03T06:44:45.720594Z","shell.execute_reply":"2024-01-03T06:44:45.757514Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Validation Set Accuracy (SVM): 0.6402\nTest Set Accuracy (SVM): 0.6760\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# Initialize the Neural Network model\nmodel = Sequential()\n\n# Add input and hidden layers\nmodel.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(Dropout(0.5))  # Dropout for regularization\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.5))  # Dropout for regularization\n\n# Add output layer\nmodel.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n\n# Compile the model\nmodel.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model on the training data\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Set Accuracy (Neural Network): {test_accuracy:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\n# Initialize the Naive Bayes model (Multinomial Naive Bayes)\nnaive_bayes_model = MultinomialNB()\n\n# Train the model on the training data\nnaive_bayes_model.fit(X_train, y_train)\n\n# Evaluate the model on the validation set\nvalidation_accuracy = naive_bayes_model.score(X_val, y_val)\nprint(f\"Validation Set Accuracy (Naive Bayes): {validation_accuracy:.4f}\")\n\n# Evaluate the final performance on the test set\ntest_accuracy = naive_bayes_model.score(X_test, y_test)\nprint(f\"Test Set Accuracy (Naive Bayes): {test_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:46:37.891062Z","iopub.execute_input":"2024-01-03T06:46:37.891631Z","iopub.status.idle":"2024-01-03T06:46:37.918865Z","shell.execute_reply.started":"2024-01-03T06:46:37.891592Z","shell.execute_reply":"2024-01-03T06:46:37.917565Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Validation Set Accuracy (Naive Bayes): 0.7523\nTest Set Accuracy (Naive Bayes): 0.7486\n","output_type":"stream"}]},{"cell_type":"code","source":"import xgboost as xgb\n\n# Initialize the XGBoost Classifier model\nxgb_model = xgb.XGBClassifier(random_state=42)\n\n# Train the model on the training data\nxgb_model.fit(X_train, y_train)\n\n# Evaluate the model on the validation set\nvalidation_accuracy = xgb_model.score(X_val, y_val)\nprint(f\"Validation Set Accuracy (XGBoost): {validation_accuracy:.4f}\")\n\n# Evaluate the final performance on the test set\ntest_accuracy = xgb_model.score(X_test, y_test)\nprint(f\"Test Set Accuracy (XGBoost): {test_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:47:18.761330Z","iopub.execute_input":"2024-01-03T06:47:18.761818Z","iopub.status.idle":"2024-01-03T06:47:19.100244Z","shell.execute_reply.started":"2024-01-03T06:47:18.761781Z","shell.execute_reply":"2024-01-03T06:47:19.099414Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Validation Set Accuracy (XGBoost): 0.7944\nTest Set Accuracy (XGBoost): 0.8380\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}